{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Projet 2 : Estimation du SOC par Intelligence Artificielle - Modèle MLP\n",
                "\n",
                "Ce notebook implémente un réseau de neurones **Fully Connected (MLP)** pour estimer le State of Charge (SOC) d'une batterie.\n",
                "\n",
                "## Objectifs\n",
                "1. Chargement et analyse des données.\n",
                "2. Prétraitement (Normalisation, Segmentation).\n",
                "3. Construction et entraînement du modèle MLP.\n",
                "4. Évaluation des performances (MAE, RMSE, R²)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Installation plus robuste des bibliothèques nécessaires\n",
                "import sys\n",
                "!{sys.executable} -m pip install tensorflow pandas numpy matplotlib seaborn scikit-learn\n",
                "\n",
                "print(\"Installation terminée. SI C'EST LA PREMIÈRE FOIS, VEUILLEZ REDÉMARRER LE NOYAU (KERNEL -> RESTART) avant d'exécuter la suite.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Importations et Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "import math\n",
                "import os\n",
                "\n",
                "# Vérification GPU\n",
                "print(\"TensorFlow version:\", tf.__version__)\n",
                "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Chargement des Données\n",
                "Assurez-vous que le fichier `.csv` est accessible."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Chemin du fichier (à adapter selon votre environnement)\n",
                "file_path = 'battery_data_csv_forEstimation.csv'\n",
                "\n",
                "if os.path.exists(file_path):\n",
                "    df = pd.read_csv(file_path)\n",
                "    print(f\"Données chargées. Taille: {df.shape}\")\n",
                "else:\n",
                "    print(\"Erreur : Fichier non trouvé. Veuillez vérifier le chemin ou uploader le fichier.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Aperçu des données\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistiques descriptives\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualisation rapide\n",
                "plt.figure(figsize=(15, 10))\n",
                "plt.subplot(4, 1, 1)\n",
                "plt.plot(df['Current'], label='Current', color='blue')\n",
                "plt.legend()\n",
                "plt.subplot(4, 1, 2)\n",
                "plt.plot(df['Voltage'], label='Voltage', color='orange')\n",
                "plt.legend()\n",
                "plt.subplot(4, 1, 3)\n",
                "plt.plot(df['Temperature'], label='Temperature', color='green')\n",
                "plt.legend()\n",
                "plt.subplot(4, 1, 4)\n",
                "plt.plot(df['SOC'], label='SOC', color='red')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prétraitement pour le MLP\n",
                "Pour le MLP, nous allons utiliser une fenêtre glissante aplatie.\n",
                "\n",
                "- **Normalisation** : MinMaxScaler pour mettre toutes les variables entre 0 et 1.\n",
                "- **Fenêtrage** : Transformation des données en `(samples, window_size * features)`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sélection des features et de la cible\n",
                "features = ['Current', 'Voltage', 'Temperature']\n",
                "target = 'SOC'\n",
                "\n",
                "data = df[features + [target]].values\n",
                "\n",
                "# Normalisation\n",
                "scaler = MinMaxScaler(feature_range=(0, 1))\n",
                "data_scaled = scaler.fit_transform(data)\n",
                "\n",
                "print(\"Données normalisées :\", data_scaled.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_dataset_mlp(dataset, look_back=1):\n",
                "    X, Y = [], []\n",
                "    for i in range(len(dataset) - look_back):\n",
                "        # Features : Colonnes 0, 1, 2 sur la fenêtre temporelle aplatie\n",
                "        a = dataset[i:(i + look_back), 0:3] \n",
                "        X.append(a.flatten()) \n",
                "        Y.append(dataset[i + look_back, 3]) # SOC cible\n",
                "    return np.array(X), np.array(Y)\n",
                "\n",
                "# Paramètres\n",
                "LOOK_BACK = 20 # Taille de la fenêtre historique\n",
                "\n",
                "X, Y = create_dataset_mlp(data_scaled, LOOK_BACK)\n",
                "\n",
                "print(\"Shape X :\", X.shape)\n",
                "print(\"Shape Y :\", Y.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split Train/Val/Test (70% / 15% / 15%)\n",
                "total_size = len(X)\n",
                "train_size = int(total_size * 0.7)\n",
                "val_size = int(total_size * 0.15)\n",
                "\n",
                "X_train, Y_train = X[:train_size], Y[:train_size]\n",
                "X_val, Y_val = X[train_size:train_size+val_size], Y[train_size:train_size+val_size]\n",
                "X_test, Y_test = X[train_size+val_size:], Y[train_size+val_size:]\n",
                "\n",
                "print(f\"Train shape: {X_train.shape}\")\n",
                "print(f\"Val shape: {X_val.shape}\")\n",
                "print(f\"Test shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Construction et Entraînement du Modèle MLP"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_mlp_model(input_dim):\n",
                "    model = Sequential()\n",
                "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
                "    model.add(Dropout(0.2))\n",
                "    model.add(Dense(64, activation='relu'))\n",
                "    model.add(Dropout(0.2))\n",
                "    model.add(Dense(32, activation='relu'))\n",
                "    model.add(Dense(1, activation='sigmoid')) # ACTIVATION SIGMOID : Plus précis pour atteindre les min/max (0 et 1) que sigmoid\n",
                "    \n",
                "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
                "    return model\n",
                "\n",
                "model_mlp = build_mlp_model(X_train.shape[1])\n",
                "model_mlp.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entraînement\n",
                "history_mlp = model_mlp.fit(\n",
                "    X_train, Y_train,\n",
                "    epochs=50, # 50 Époques\n",
                "    batch_size=64,\n",
                "    validation_data=(X_val, Y_val),\n",
                "    verbose=1,\n",
                "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualisation de la perte (Loss)\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(history_mlp.history['loss'], label='Train Loss')\n",
                "plt.plot(history_mlp.history['val_loss'], label='Validation Loss')\n",
                "plt.title('Courbe de Loss (MLP)')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Loss (MSE)')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Évaluation et Résultats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prédictions sur le jeu de test\n",
                "predictions_mlp = model_mlp.predict(X_test)\n",
                "\n",
                "# Métriques\n",
                "mae = mean_absolute_error(Y_test, predictions_mlp)\n",
                "rmse = math.sqrt(mean_squared_error(Y_test, predictions_mlp)) # Correction: predictions_mlp ici, pas predictions_lstm\n",
                "r2 = r2_score(Y_test, predictions_mlp)\n",
                "\n",
                "print(f\"MAE: {mae:.4f}\")\n",
                "print(f\"RMSE: {rmse:.4f}\")\n",
                "print(f\"R²: {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tracé SOC réel vs Estimé\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.plot(Y_test, label='SOC Réel', color='black', linewidth=2)\n",
                "plt.plot(predictions_mlp, label='Estimation MLP', color='red', linestyle='--')\n",
                "plt.title('SOC Réel vs Estimé (MLP)')\n",
                "plt.xlabel('Temps (échantillons)')\n",
                "plt.ylabel('SOC Normalisé')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Erreur d'estimation\n",
                "error = Y_test - predictions_mlp.flatten()\n",
                "plt.figure(figsize=(15, 4))\n",
                "plt.plot(error, color='purple')\n",
                "plt.title(\"Erreur d'estimation (Réel - Estimé)\")\n",
                "plt.ylabel('Erreur')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sauvegarde du modèle\n",
                "model_mlp.save('mlp_soc_model.h5')\n",
                "print(\"Modèle MLP sauvegardé.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}