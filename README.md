# Estimation du State of Charge (SOC) par Intelligence Artificielle

Ce projet vise √† estimer l'√©tat de charge (State of Charge - SOC) d'une batterie en utilisant des techniques d'apprentissage profond (Deep Learning). Deux approches distinctes sont impl√©ment√©es et compar√©es : un Perceptron Multicouche (MLP) et un r√©seau R√©current √† M√©moire Court et Long Terme (LSTM).

## üìÇ Structure du Projet

Le projet est organis√© autour de deux notebooks Jupyter principaux, chacun d√©di√© √† une architecture de mod√®le sp√©cifique, et d'un jeu de donn√©es.

*   **`Estimation_SOC_MLP.ipynb`** : Notebook pour l'entra√Ænement et l'√©valuation du mod√®le **MLP** (Multi-Layer Perceptron). Ce mod√®le utilise une fen√™tre temporelle "aplatie" pour pr√©dire le SOC.
*   **`Estimation_SOC_LSTM.ipynb`** : Notebook pour l'entra√Ænement et l'√©valuation du mod√®le **LSTM** (Long Short-Term Memory). Ce mod√®le exploite la nature s√©quentielle des donn√©es temporelles pour une estimation plus robuste.
*   **`battery_data_csv_forEstimation.csv`** : Le fichier CSV contenant les donn√©es brutes de capteurs (Courant, Tension, Temp√©rature) et le SOC cible.

## üìä Donn√©es

Le dataset contient des enregistrements temporels des param√®tres de la batterie :
*   **Current** (Courant)
*   **Voltage** (Tension)
*   **Temperature** (Temp√©rature)
*   **SOC** (State of Charge - Cible √† pr√©dire)

Un pr√©traitement est appliqu√© dans chaque notebook pour normaliser ces donn√©es (Mise √† l'√©chelle MinMax entre 0 et 1) et les structurer en s√©quences (fen√™tres glissantes) adapt√©es √† l'apprentissage supervis√©.

## üöÄ Installation et Utilisation

Les notebooks sont con√ßus pour √™tre autonomes (par exemple sur Google Colab ou Jupyter Lab local).

### 1. Pr√©-requis
Une cellule d'installation automatique des d√©pendances est incluse au d√©but de chaque notebook. Elle installe :
*   `tensorflow`
*   `pandas`
*   `numpy`
*   `matplotlib`
*   `seaborn`
*   `scikit-learn`

### 2. Ex√©cution
1.  Ouvrez l'un des notebooks (`Estimation_SOC_MLP.ipynb` ou `Estimation_SOC_LSTM.ipynb`).
2.  Ex√©cutez la **premi√®re cellule** pour installer les biblioth√®ques n√©cessaires.
3.  **IMPORTANT** : Une fois l'installation termin√©e, **red√©marrez le noyau (Kernel)** de votre environnement (Menu `Kernel` > `Restart Kernel`) pour prendre en compte les nouvelles installations.
4.  Ex√©cutez toutes les cellules restantes (Menu `Run` > `Run All` ou ex√©cution cellule par cellule).

## üß† Mod√®les et Architecture

### MLP (Multi-Layer Perceptron)
*   **Entr√©e** : Fen√™tre de temps fixe, aplatie en un vecteur 1D.
*   **Architecture** : Couches Denses (Fully Connected) avec activation ReLU et Dropout pour la r√©gularisation.
*   **Sortie** : Activation **Sigmo√Øde** pour garantir une estimation strictement born√©e entre 0 et 1 (SOC).

### LSTM (Long Short-Term Memory)
*   **Entr√©e** : S√©quence temporelle 3D (Samples, TimeSteps, Features).
*   **Architecture** : Couches LSTM permettant de capturer les d√©pendances temporelles √† long terme, suivies de couches Denses.
*   **Sortie** : Activation **Sigmo√Øde**.

## üìà R√©sultats et √âvaluation

Les notebooks g√©n√®rent automatiquement :
*   Des courbes de perte (Loss) pour surveiller l'entra√Ænement.
*   Des graphiques comparatifs entre le **SOC R√©el** et le **SOC Estim√©** sur un jeu de test.
*   Des m√©triques de performance pr√©cises :
    *   **MAE** (Mean Absolute Error)
    *   **RMSE** (Root Mean Squared Error)
    *   **R¬≤** (Coefficient de d√©termination)

L'utilisation de l'activation **Sigmo√Øde** en sortie permet de respecter les contraintes physiques du SOC (0% √† 100%). L'entra√Ænement sur 50 √©poques assure une bonne convergence.

## üõ† Auteur
Projet r√©alis√© dans le cadre de l'estimation de SOC par IA.
